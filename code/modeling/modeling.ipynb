{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# modeling.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import logging\n",
    "import math\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import neighbors, model_selection, preprocessing\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.exceptions import UndefinedMetricWarning\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.utils._testing import ignore_warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# !!! WARNING !!!\n",
    "\n",
    "Setting the value of LIMITER to less than about 50 or so will lead to long processing times. LIMITER value of 1 trains the models against the entire data set. \n",
    "\n",
    "Make sure to run `pip install -r requirements.txt` before executing this notebook.\n",
    "\n",
    "You've been warned :) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "LIMITER = 1000 # number of observations in dataset / limiter :: applies to all models\n",
    "PATH = \"../../data/clean_formatted/20210712_214459_formatted-data.csv\"\n",
    "REPORT_PATH = \"../../data/results/report.csv\" # file saving the performance metrics for each model for later processing\n",
    "K_VALUE = 4 # used in K-Nearest Neighbor Regressor\n",
    "ESTIMATORS = 150 # used for Random Forest Regressor\n",
    "LAYERS = 20 # used for Multi-layer Perceptron Regressor\n",
    "LAYER_SIZE = 60 # used for Multi-layer Perceptron Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shared Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv(path):\n",
    "    ''' read_csv reads csv from provided path and return dataframe '''\n",
    "    return pd.read_csv(path)\n",
    "\n",
    "def clean_copy(data_frame):\n",
    "    ''' clean_copy copies the given data frame and drops player_id '''\n",
    "    wdf = data_frame.copy()\n",
    "    wdf = wdf.drop('player_id', axis=1)\n",
    "    return wdf\n",
    "\n",
    "def split_data(data_frame):\n",
    "    ''' splits dataframe into predictor and target dataframes '''\n",
    "    predictors = data_frame.drop('fs_total', axis=1)\n",
    "    target = data_frame['fs_total']\n",
    "    return predictors, target\n",
    "\n",
    "def save(path, contents):\n",
    "    # Open file in append mode\n",
    "    with open(path, 'a+', newline='\\n') as write_obj:\n",
    "        # Create a writer object from csv module\n",
    "        csv_writer = csv.writer(write_obj)\n",
    "        # Add contents of list as last row in the csv file\n",
    "        csv_writer.writerow(contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbors Regression (KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn(description, K_VALUE, predictors, target):\n",
    "    ''' uses 5-fold cross validation to create and save MLPC model '''\n",
    "    kfold = model_selection.KFold(5, shuffle=True, random_state=2)\n",
    "\n",
    "    rmse, mse, r2 = [], [], []\n",
    "\n",
    "    for train_idx, test_idx in kfold.split(predictors):\n",
    "        predictors_train, predictors_test = predictors[train_idx], predictors[test_idx]\n",
    "        target_train, target_test = target[train_idx], target[test_idx]\n",
    "\n",
    "        knn_regression = neighbors.KNeighborsRegressor(n_neighbors=K_VALUE, weights='uniform')\n",
    "\n",
    "        knn_regression.fit(predictors_train, target_train)\n",
    "\n",
    "        rmse += [math.sqrt(np.mean((knn_regression.predict(predictors_test) - target_test) ** 2))]\n",
    "        mse += [np.mean((knn_regression.predict(predictors_test) - target_test) ** 2)]\n",
    "        r2 += [knn_regression.score(predictors_test, target_test)]\n",
    "\n",
    "    now = datetime.now()\n",
    "    current_time = now.strftime(\"%D %H:%M:%S\")\n",
    "    results = [\n",
    "        description,\n",
    "        \"{:.4f}\".format(np.mean(rmse)), # rmse\n",
    "        \"{:.4f}\".format(np.std(rmse)), # rmse variance\n",
    "        \"{:.4f}\".format(np.mean(mse)), # mse\n",
    "        \"{:.4f}\".format(np.std(mse)), # mse variance\n",
    "        \"{:.4f}\".format(np.mean(r2)), #r2\n",
    "        \"{:.4f}\".format(np.std(r2)), #r2 variance\n",
    "        \"{}\".format(len(predictors)), #num records analyzed\n",
    "        \"{}\".format(current_time) #time of execution\n",
    "    ]\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Regression (RFR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rfr(description, n_estimators, predictors, target):\n",
    "    ''' uses 5-fold cross validation to create and save rfr model '''\n",
    "    kfold = model_selection.KFold(5, shuffle=True, random_state=2)\n",
    "\n",
    "    rmse, mse, r2 = [], [], []\n",
    "\n",
    "    for train_idx, test_idx in kfold.split(predictors):\n",
    "        predictors_train, predictors_test = predictors[train_idx], predictors[test_idx]\n",
    "        target_train, target_test = target[train_idx], target[test_idx]\n",
    "\n",
    "        regressor = RandomForestRegressor(n_estimators=n_estimators)\n",
    "        regressor.fit(predictors_train, target_train)\n",
    "\n",
    "        rmse += [math.sqrt(np.mean((regressor.predict(predictors_test) - target_test) ** 2))]\n",
    "        mse += [np.mean((regressor.predict(predictors_test) - target_test) ** 2)]\n",
    "        r2 += [regressor.score(predictors_test, target_test)]\n",
    "\n",
    "    now = datetime.now()\n",
    "    current_time = now.strftime(\"%D %H:%M:%S\")\n",
    "    results = [\n",
    "        description,\n",
    "        \"{:.4f}\".format(np.mean(rmse)), # rmse\n",
    "        \"{:.4f}\".format(np.std(rmse)), # rmse variance\n",
    "        \"{:.4f}\".format(np.mean(mse)), # mse\n",
    "        \"{:.4f}\".format(np.std(mse)), # mse variance\n",
    "        \"{:.4f}\".format(np.mean(r2)), #r2\n",
    "        \"{:.4f}\".format(np.std(r2)), #r2 variance\n",
    "        \"{}\".format(len(predictors)), #num records analyzed\n",
    "        \"{}\".format(current_time) #time of execution\n",
    "    ]\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Regression (DTR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dtr(description, predictors, target):\n",
    "    ''' uses 5-fold cross validation to create and save MLPC model '''\n",
    "    kfold = model_selection.KFold(5, shuffle=True, random_state=2)\n",
    "\n",
    "    rmse, mse, r2 = [], [], []\n",
    "\n",
    "    for train_idx, test_idx in kfold.split(predictors):\n",
    "        predictors_train, predictors_test = predictors[train_idx], predictors[test_idx]\n",
    "        target_train, target_test = target[train_idx], target[test_idx]\n",
    "\n",
    "        regressor = DecisionTreeRegressor().fit(predictors_train, target_train)\n",
    "\n",
    "        rmse += [math.sqrt(np.mean((regressor.predict(predictors_test) - target_test) ** 2))]\n",
    "        mse += [np.mean((regressor.predict(predictors_test) - target_test) ** 2)]\n",
    "        r2 += [regressor.score(predictors_test, target_test)]\n",
    "\n",
    "    now = datetime.now()\n",
    "    current_time = now.strftime(\"%D %H:%M:%S\")\n",
    "    results = [\n",
    "        description,\n",
    "        \"{:.4f}\".format(np.mean(rmse)), # rmse\n",
    "        \"{:.4f}\".format(np.std(rmse)), # rmse variance\n",
    "        \"{:.4f}\".format(np.mean(mse)), # mse\n",
    "        \"{:.4f}\".format(np.std(mse)), # mse variance\n",
    "        \"{:.4f}\".format(np.mean(r2)), #r2\n",
    "        \"{:.4f}\".format(np.std(r2)), #r2 variance\n",
    "        \"{}\".format(len(predictors)), #num records analyzed\n",
    "        \"{}\".format(current_time) #time of execution\n",
    "    ]\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple Linear Regression (MLR) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlr(description, predictors, target):\n",
    "    ''' uses 5-fold cross validation to create and save MLPC model '''\n",
    "    kfold = model_selection.KFold(5, shuffle=True, random_state=2)\n",
    "\n",
    "    rmse, mse, r2 = [], [], []\n",
    "\n",
    "    for train_idx, test_idx in kfold.split(predictors):\n",
    "        predictors_train, predictors_test = predictors[train_idx], predictors[test_idx]\n",
    "        target_train, target_test = target[train_idx], target[test_idx]\n",
    "\n",
    "        regressor = LinearRegression().fit(predictors_train, target_train)\n",
    "\n",
    "        rmse += [math.sqrt(np.mean((regressor.predict(predictors_test) - target_test) ** 2))]\n",
    "        mse += [np.mean((regressor.predict(predictors_test) - target_test) ** 2)]\n",
    "        r2 += [regressor.score(predictors_test, target_test)]\n",
    "\n",
    "    now = datetime.now()\n",
    "    current_time = now.strftime(\"%D %H:%M:%S\")\n",
    "    results = [\n",
    "        description,\n",
    "        \"{:.4f}\".format(np.mean(rmse)), # rmse\n",
    "        \"{:.4f}\".format(np.std(rmse)), # rmse variance\n",
    "        \"{:.4f}\".format(np.mean(mse)), # mse\n",
    "        \"{:.4f}\".format(np.std(mse)), # mse variance\n",
    "        \"{:.4f}\".format(np.mean(r2)), #r2\n",
    "        \"{:.4f}\".format(np.std(r2)), #r2 variance\n",
    "        \"{}\".format(len(predictors)), #num records analyzed\n",
    "        \"{}\".format(current_time) #time of execution\n",
    "    ]\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-layer Perceptron Regression (MLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp(description, arch, activation, predictors, target):\n",
    "    ''' uses 5-fold cross validation to create and save MLPC model '''\n",
    "    kfold = model_selection.KFold(5, shuffle=True, random_state=2)\n",
    "\n",
    "    rmse, mse, r2 = [], [], []\n",
    "\n",
    "    for train_idx, test_idx in kfold.split(predictors):\n",
    "        predictors_train, predictors_test = predictors[train_idx], predictors[test_idx]\n",
    "        target_train, target_test = target[train_idx], target[test_idx]\n",
    "\n",
    "        mlp_clf = MLPRegressor(\n",
    "            hidden_layer_sizes=arch,\n",
    "            max_iter=2000,\n",
    "            activation=activation,\n",
    "            random_state=2,\n",
    "            solver='lbfgs')\n",
    "\n",
    "        with ignore_warnings(category=UndefinedMetricWarning):\n",
    "\n",
    "            predictors_scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "            predictors_train = predictors_scaler.fit_transform(predictors_train)\n",
    "\n",
    "            mlp_clf.fit(predictors_train, target_train)\n",
    "\n",
    "            predictors_test = predictors_scaler.transform(predictors_test)\n",
    "            target_prediction = mlp_clf.predict(predictors_test)\n",
    "\n",
    "            rmse += [math.sqrt((np.mean(target_prediction - target_test) ** 2))]\n",
    "            mse += [np.mean((target_prediction - target_test) ** 2)]\n",
    "            r2 += [mlp_clf.score(predictors_test, target_test)]\n",
    "\n",
    "    now = datetime.now()\n",
    "    current_time = now.strftime(\"%D %H:%M:%S\")\n",
    "    results = [\n",
    "        description,\n",
    "        \"{:.4f}\".format(np.mean(rmse)), # rmse\n",
    "        \"{:.4f}\".format(np.std(rmse)), # rmse variance\n",
    "        \"{:.4f}\".format(np.mean(mse)), # mse\n",
    "        \"{:.4f}\".format(np.std(mse)), # mse variance\n",
    "        \"{:.4f}\".format(np.mean(r2)), #r2\n",
    "        \"{:.4f}\".format(np.std(r2)), #r2 variance\n",
    "        \"{}\".format(len(predictors)), #num records analyzed\n",
    "        \"{}\".format(current_time) #time of execution\n",
    "    ]\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Asses Best Values (K, Estimators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO ::: starting knn.py\n",
      "INFO ::: read in 200596 records to data frame with 205 features\n",
      "INFO ::: will use 200 records for MLP Classifier\n",
      "INFO ::: converting predictors and target to numpy arrays\n",
      "WARNING ::: starting KNN Regression - good luck.\n",
      "INFO ::: KNN Regression completed, results:\n",
      "INFO ::: ['KNN Regressor, where K = 1', '3.0416', '0.6953', '9.7350', '4.2872', '0.6790', '0.1309', '200', '12/10/21 20:00:26']\n",
      "INFO ::: updating reports.csv\n",
      "WARNING ::: starting KNN Regression - good luck.\n",
      "INFO ::: KNN Regression completed, results:\n",
      "INFO ::: ['KNN Regressor, where K = 2', '3.0341', '0.8948', '10.0062', '4.9744', '0.6800', '0.1682', '200', '12/10/21 20:00:26']\n",
      "INFO ::: updating reports.csv\n",
      "WARNING ::: starting KNN Regression - good luck.\n",
      "INFO ::: KNN Regression completed, results:\n",
      "INFO ::: ['KNN Regressor, where K = 3', '2.8754', '0.9360', '9.1439', '5.0326', '0.7133', '0.1556', '200', '12/10/21 20:00:26']\n",
      "INFO ::: updating reports.csv\n",
      "WARNING ::: starting KNN Regression - good luck.\n",
      "INFO ::: KNN Regression completed, results:\n",
      "INFO ::: ['KNN Regressor, where K = 4', '2.8586', '0.7835', '8.7853', '4.0419', '0.7184', '0.1341', '200', '12/10/21 20:00:26']\n",
      "INFO ::: updating reports.csv\n",
      "WARNING ::: starting KNN Regression - good luck.\n",
      "INFO ::: KNN Regression completed, results:\n",
      "INFO ::: ['KNN Regressor, where K = 5', '2.9796', '0.7419', '9.4286', '4.4576', '0.7005', '0.1141', '200', '12/10/21 20:00:26']\n",
      "INFO ::: updating reports.csv\n",
      "WARNING ::: starting KNN Regression - good luck.\n",
      "INFO ::: KNN Regression completed, results:\n",
      "INFO ::: ['KNN Regressor, where K = 6', '2.9434', '0.8263', '9.3463', '4.9494', '0.7079', '0.1225', '200', '12/10/21 20:00:26']\n",
      "INFO ::: updating reports.csv\n",
      "WARNING ::: starting KNN Regression - good luck.\n",
      "INFO ::: KNN Regression completed, results:\n",
      "INFO ::: ['KNN Regressor, where K = 7', '2.8734', '0.8391', '8.9606', '5.0858', '0.7184', '0.1314', '200', '12/10/21 20:00:26']\n",
      "INFO ::: updating reports.csv\n",
      "WARNING ::: starting KNN Regression - good luck.\n",
      "INFO ::: KNN Regression completed, results:\n",
      "INFO ::: ['KNN Regressor, where K = 8', '2.9270', '0.8751', '9.3331', '5.4598', '0.7110', '0.1272', '200', '12/10/21 20:00:26']\n",
      "INFO ::: updating reports.csv\n",
      "WARNING ::: starting KNN Regression - good luck.\n",
      "INFO ::: KNN Regression completed, results:\n",
      "INFO ::: ['KNN Regressor, where K = 9', '3.0105', '0.9698', '10.0038', '6.2036', '0.6935', '0.1457', '200', '12/10/21 20:00:27']\n",
      "INFO ::: updating reports.csv\n",
      "WARNING ::: starting KNN Regression - good luck.\n",
      "INFO ::: KNN Regression completed, results:\n",
      "INFO ::: ['KNN Regressor, where K = 10', '3.0636', '0.9965', '10.3785', '6.5165', '0.6818', '0.1549', '200', '12/10/21 20:00:27']\n",
      "INFO ::: updating reports.csv\n",
      "WARNING ::: starting KNN Regression - good luck.\n",
      "INFO ::: KNN Regression completed, results:\n",
      "INFO ::: ['KNN Regressor, where K = 11', '3.0666', '1.0148', '10.4340', '6.8170', '0.6869', '0.1365', '200', '12/10/21 20:00:27']\n",
      "INFO ::: updating reports.csv\n",
      "WARNING ::: starting KNN Regression - good luck.\n",
      "INFO ::: KNN Regression completed, results:\n",
      "INFO ::: ['KNN Regressor, where K = 12', '3.1286', '1.0380', '10.8653', '7.1934', '0.6781', '0.1277', '200', '12/10/21 20:00:27']\n",
      "INFO ::: updating reports.csv\n",
      "WARNING ::: starting KNN Regression - good luck.\n",
      "INFO ::: KNN Regression completed, results:\n",
      "INFO ::: ['KNN Regressor, where K = 13', '3.1837', '1.0337', '11.2043', '7.2490', '0.6677', '0.1256', '200', '12/10/21 20:00:27']\n",
      "INFO ::: updating reports.csv\n",
      "WARNING ::: starting KNN Regression - good luck.\n",
      "INFO ::: KNN Regression completed, results:\n",
      "INFO ::: ['KNN Regressor, where K = 14', '3.2517', '1.0598', '11.6964', '7.6421', '0.6560', '0.1218', '200', '12/10/21 20:00:27']\n",
      "INFO ::: updating reports.csv\n",
      "WARNING ::: starting KNN Regression - good luck.\n",
      "INFO ::: KNN Regression completed, results:\n",
      "INFO ::: ['KNN Regressor, where K = 15', '3.3016', '1.1311', '12.1802', '8.1366', '0.6461', '0.1328', '200', '12/10/21 20:00:27']\n",
      "INFO ::: updating reports.csv\n",
      "WARNING ::: starting KNN Regression - good luck.\n",
      "INFO ::: KNN Regression completed, results:\n",
      "INFO ::: ['KNN Regressor, where K = 16', '3.3909', '1.1349', '12.7863', '8.2696', '0.6271', '0.1341', '200', '12/10/21 20:00:27']\n",
      "INFO ::: updating reports.csv\n",
      "WARNING ::: starting KNN Regression - good luck.\n",
      "INFO ::: KNN Regression completed, results:\n",
      "INFO ::: ['KNN Regressor, where K = 17', '3.4374', '1.1937', '13.2408', '8.8680', '0.6179', '0.1409', '200', '12/10/21 20:00:27']\n",
      "INFO ::: updating reports.csv\n",
      "WARNING ::: starting KNN Regression - good luck.\n",
      "INFO ::: KNN Regression completed, results:\n",
      "INFO ::: ['KNN Regressor, where K = 18', '3.5022', '1.1966', '13.6972', '9.0859', '0.6054', '0.1364', '200', '12/10/21 20:00:27']\n",
      "INFO ::: updating reports.csv\n",
      "WARNING ::: starting KNN Regression - good luck.\n",
      "INFO ::: KNN Regression completed, results:\n",
      "INFO ::: ['KNN Regressor, where K = 19', '3.5620', '1.2299', '14.2005', '9.5197', '0.5932', '0.1386', '200', '12/10/21 20:00:27']\n",
      "INFO ::: updating reports.csv\n",
      "WARNING ::: starting KNN Regression - good luck.\n",
      "INFO ::: KNN Regression completed, results:\n",
      "INFO ::: ['KNN Regressor, where K = 20', '3.6173', '1.2670', '14.6902', '10.0352', '0.5823', '0.1404', '200', '12/10/21 20:00:27']\n",
      "INFO ::: updating reports.csv\n",
      "WARNING ::: starting KNN Regression - good luck.\n",
      "INFO ::: KNN Regression completed, results:\n",
      "INFO ::: ['KNN Regressor, where K = 21', '3.6560', '1.2869', '15.0228', '10.3028', '0.5749', '0.1398', '200', '12/10/21 20:00:27']\n",
      "INFO ::: updating reports.csv\n",
      "WARNING ::: starting KNN Regression - good luck.\n",
      "INFO ::: KNN Regression completed, results:\n",
      "INFO ::: ['KNN Regressor, where K = 22', '3.7337', '1.2925', '15.6108', '10.5177', '0.5575', '0.1384', '200', '12/10/21 20:00:27']\n",
      "INFO ::: updating reports.csv\n",
      "WARNING ::: starting KNN Regression - good luck.\n",
      "INFO ::: KNN Regression completed, results:\n",
      "INFO ::: ['KNN Regressor, where K = 23', '3.7854', '1.3094', '16.0434', '10.8974', '0.5464', '0.1378', '200', '12/10/21 20:00:27']\n",
      "INFO ::: updating reports.csv\n",
      "WARNING ::: starting KNN Regression - good luck.\n",
      "INFO ::: KNN Regression completed, results:\n",
      "INFO ::: ['KNN Regressor, where K = 24', '3.8340', '1.3200', '16.4416', '11.1441', '0.5349', '0.1393', '200', '12/10/21 20:00:27']\n",
      "INFO ::: updating reports.csv\n",
      "WARNING ::: starting KNN Regression - good luck.\n",
      "INFO ::: KNN Regression completed, results:\n",
      "INFO ::: ['KNN Regressor, where K = 25', '3.8847', '1.3316', '16.8639', '11.3926', '0.5226', '0.1413', '200', '12/10/21 20:00:27']\n",
      "INFO ::: updating reports.csv\n",
      "WARNING ::: starting Random Forest Regression - good luck.\n",
      "INFO ::: Random Forest Regression completed, results:\n",
      "INFO ::: ['Random Forest Regression, where n_estimators=50', '1.9716', '0.5190', '4.1568', '2.1858', '0.8745', '0.0258', '200', '12/10/21 20:00:28']\n",
      "INFO ::: updating reports.csv\n",
      "WARNING ::: starting Random Forest Regression - good luck.\n",
      "INFO ::: Random Forest Regression completed, results:\n",
      "INFO ::: ['Random Forest Regression, where n_estimators=100', '1.9982', '0.5761', '4.3246', '2.4575', '0.8695', '0.0412', '200', '12/10/21 20:00:29']\n",
      "INFO ::: updating reports.csv\n",
      "WARNING ::: starting Random Forest Regression - good luck.\n",
      "INFO ::: Random Forest Regression completed, results:\n",
      "INFO ::: ['Random Forest Regression, where n_estimators=150', '1.9118', '0.5033', '3.9081', '2.0436', '0.8790', '0.0392', '200', '12/10/21 20:00:31']\n",
      "INFO ::: updating reports.csv\n",
      "WARNING ::: starting Random Forest Regression - good luck.\n",
      "INFO ::: Random Forest Regression completed, results:\n",
      "INFO ::: ['Random Forest Regression, where n_estimators=200', '1.9082', '0.5128', '3.9041', '2.0518', '0.8802', '0.0372', '200', '12/10/21 20:00:32']\n",
      "INFO ::: updating reports.csv\n",
      "WARNING ::: starting Random Forest Regression - good luck.\n",
      "INFO ::: Random Forest Regression completed, results:\n",
      "INFO ::: ['Random Forest Regression, where n_estimators=250', '1.8868', '0.5177', '3.8282', '2.0782', '0.8836', '0.0341', '200', '12/10/21 20:00:34']\n",
      "INFO ::: updating reports.csv\n",
      "WARNING ::: starting Random Forest Regression - good luck.\n",
      "INFO ::: Random Forest Regression completed, results:\n",
      "INFO ::: ['Random Forest Regression, where n_estimators=300', '1.9026', '0.5147', '3.8846', '2.0352', '0.8800', '0.0415', '200', '12/10/21 20:00:37']\n",
      "INFO ::: updating reports.csv\n"
     ]
    }
   ],
   "source": [
    "# Setup\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(levelname)s ::: %(message)s\")\n",
    "\n",
    "logging.info(\"starting knn.py\")\n",
    "start = time.time()\n",
    "\n",
    "# Prepare Data\n",
    "# NOTE: this is using pre cleaned / processed data set\n",
    "data_frame = read_csv(PATH)\n",
    "logging.info(\n",
    "    \"read in %s records to data frame with %s features\",\n",
    "    len(data_frame),\n",
    "    len(data_frame.columns))\n",
    "\n",
    "size = len(data_frame) // LIMITER\n",
    "logging.info(\"will use %s records for MLP Classifier\", size)\n",
    "\n",
    "subset = data_frame.iloc[:size,]\n",
    "working_subset = clean_copy(subset)\n",
    "predictors, target = split_data(working_subset)\n",
    "\n",
    "logging.info(\"converting predictors and target to numpy arrays\")\n",
    "predictors = predictors.to_numpy()\n",
    "target = target.to_numpy()\n",
    "\n",
    "# KNN\n",
    "for i in [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25]:\n",
    "    logging.warning(\"starting KNN Regression - good luck.\")\n",
    "    knn_results = knn(\n",
    "        \"KNN Regressor, where K = \" +str(i),\n",
    "        (i),predictors, target)\n",
    "\n",
    "    logging.info(\"KNN Regression completed, results:\")\n",
    "    logging.info(knn_results)\n",
    "\n",
    "    logging.info(\"updating reports.csv\")\n",
    "    save(REPORT_PATH, knn_results)\n",
    "\n",
    "# Random Forest\n",
    "for i in [50,100,150,200,250,300]:\n",
    "    logging.warning(\"starting Random Forest Regression - good luck.\")\n",
    "    rfr_results = rfr(\n",
    "        \"Random Forest Regression, where n_estimators=\"+str(i),\n",
    "        i, predictors, target)\n",
    "\n",
    "    logging.info(\"Random Forest Regression completed, results:\")\n",
    "    logging.info(rfr_results)\n",
    "\n",
    "    logging.info(\"updating reports.csv\")\n",
    "    save(REPORT_PATH, rfr_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO ::: starting knn.py\n",
      "INFO ::: read in 200596 records to data frame with 205 features\n",
      "INFO ::: will use 200 records for MLP Classifier\n",
      "INFO ::: converting predictors and target to numpy arrays\n",
      "WARNING ::: starting KNN Regression - good luck.\n",
      "INFO ::: KNN Regression completed, results:\n",
      "INFO ::: ['KNN Regressor, where K = 4', '2.8586', '0.7835', '8.7853', '4.0419', '0.7184', '0.1341', '200', '12/10/21 20:00:54']\n",
      "INFO ::: updating reports.csv\n",
      "WARNING ::: starting Random Forest Regression - good luck.\n",
      "INFO ::: Random Forest Regression completed, results:\n",
      "INFO ::: ['Random Forest Regression, where n_estimators=150', '1.8760', '0.5084', '3.7779', '2.0806', '0.8855', '0.0283', '200', '12/10/21 20:00:56']\n",
      "INFO ::: updating reports.csv\n",
      "WARNING ::: starting Decision Tree Regression - good luck.\n",
      "INFO ::: Decision Tree Regression completed, results:\n",
      "INFO ::: ['Decision Tree Regression', '2.2244', '0.7597', '5.5250', '3.3412', '0.8044', '0.1707', '200', '12/10/21 20:00:56']\n",
      "INFO ::: updating reports.csv\n",
      "WARNING ::: starting Multiple Linear Regression - good luck.\n",
      "INFO ::: Multiple Linear Regression completed, results:\n",
      "INFO ::: ['Multiple Linear Regression', '0.0000', '0.0000', '0.0000', '0.0000', '1.0000', '0.0000', '200', '12/10/21 20:00:56']\n",
      "INFO ::: updating reports.csv\n",
      "WARNING ::: starting MLP Regressor - good luck.\n",
      "INFO ::: MLP Regressor completed, results:\n",
      "INFO ::: ['MLP Regression using Relu: 20 hidden layers with 60 nodes per layer', '0.3352', '0.2972', '2.0274', '1.1696', '0.9318', '0.0445', '200', '12/10/21 20:00:58']\n",
      "INFO ::: updating reports.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "executed knn.py in : 20.885556936264038\n"
     ]
    }
   ],
   "source": [
    "# Setup\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(levelname)s ::: %(message)s\")\n",
    "\n",
    "logging.info(\"starting knn.py\")\n",
    "start = time.time()\n",
    "\n",
    "# Prepare Data\n",
    "# NOTE: this is using pre cleaned / processed data set\n",
    "data_frame = read_csv(PATH)\n",
    "logging.info(\n",
    "    \"read in %s records to data frame with %s features\",\n",
    "    len(data_frame),\n",
    "    len(data_frame.columns))\n",
    "\n",
    "size = len(data_frame) // LIMITER\n",
    "logging.info(\"will use %s records for MLP Classifier\", size)\n",
    "\n",
    "subset = data_frame.iloc[:size,]\n",
    "working_subset = clean_copy(subset)\n",
    "predictors, target = split_data(working_subset)\n",
    "\n",
    "logging.info(\"converting predictors and target to numpy arrays\")\n",
    "predictors = predictors.to_numpy()\n",
    "target = target.to_numpy()\n",
    "\n",
    "# KNN\n",
    "logging.warning(\"starting KNN Regression - good luck.\")\n",
    "knn_results = knn(\n",
    "    \"KNN Regressor, where K = \" +str(K_VALUE),\n",
    "    (K_VALUE),predictors, target)\n",
    "\n",
    "logging.info(\"KNN Regression completed, results:\")\n",
    "logging.info(knn_results)\n",
    "\n",
    "logging.info(\"updating reports.csv\")\n",
    "save(REPORT_PATH, knn_results)\n",
    "\n",
    "# Random Forest\n",
    "logging.warning(\"starting Random Forest Regression - good luck.\")\n",
    "rfr_results = rfr(\n",
    "    \"Random Forest Regression, where n_estimators=\"+str(ESTIMATORS),\n",
    "    ESTIMATORS, predictors, target)\n",
    "\n",
    "logging.info(\"Random Forest Regression completed, results:\")\n",
    "logging.info(rfr_results)\n",
    "\n",
    "logging.info(\"updating reports.csv\")\n",
    "save(REPORT_PATH, rfr_results)\n",
    "\n",
    "# Decision Tree\n",
    "logging.warning(\"starting Decision Tree Regression - good luck.\")\n",
    "dtr_results = dtr(\"Decision Tree Regression\",predictors, target)\n",
    "\n",
    "logging.info(\"Decision Tree Regression completed, results:\")\n",
    "logging.info(dtr_results)\n",
    "\n",
    "logging.info(\"updating reports.csv\")\n",
    "save(REPORT_PATH, dtr_results)\n",
    "\n",
    "# Multiple Linear Regression\n",
    "logging.warning(\"starting Multiple Linear Regression - good luck.\")\n",
    "mlr_results = mlr(\"Multiple Linear Regression\",predictors, target)\n",
    "\n",
    "logging.info(\"Multiple Linear Regression completed, results:\")\n",
    "logging.info(mlr_results)\n",
    "\n",
    "logging.info(\"updating reports.csv\")\n",
    "save(REPORT_PATH, mlr_results)\n",
    "\n",
    "# Multi-layer Perceptron Regression\n",
    "logging.warning(\"starting MLP Regressor - good luck.\")\n",
    "mlp_results = mlp(\n",
    "    \"MLP Regression using Relu: \" +str(LAYERS)+\" hidden layers with \"+str(LAYER_SIZE)+\n",
    "    \" nodes per layer\",\n",
    "    (LAYERS,LAYER_SIZE), \"relu\", predictors, target)\n",
    "\n",
    "logging.info(\"MLP Regressor completed, results:\")\n",
    "logging.info(mlp_results)\n",
    "\n",
    "logging.info(\"updating reports.csv\")\n",
    "save(REPORT_PATH, mlp_results)\n",
    "\n",
    "end = time.time()\n",
    "print(\"executed knn.py in :\", end-start)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ac3fb6aff13dfbb5032192ec4d343075557d22c400527e20c4a164465d089651"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
